{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dul9Rg0cIxW",
        "outputId": "9f1572ed-e5d9-48b5-8aeb-5688aa8d7449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rg2_H4dUbybo",
        "outputId": "682ad0cd-81c6-472a-ea3c-8e1abc3655b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'topic_1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Replace with your actual URI\n",
        "#uri = \"mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority\"\n",
        "uri=\"mongodb+srv://suvedya2404:Suvedya%4024@cluster0.2iosrcb.mongodb.net/\"\n",
        "\n",
        "client = MongoClient(uri)\n",
        "db = client[\"test_database\"]\n",
        "collection = db[\"test_collection\"]\n",
        "collection.create_index(\"topic\", unique=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pymongo google-generativeai"
      ],
      "metadata": {
        "id": "rVv3BUwkcEAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8adbd68-e8de-4770-fbca-3e53dce00b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.12.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "# ------------------ CONFIG ------------------ #\n",
        "\n",
        "# Gemini API key\n",
        "api_key = \"AIzaSyCRePOXa5qHS39yIy33Bp0dc36YehsL1pA\"\n",
        "\n",
        "# MongoDB Atlas connection\n",
        "uri = \"mongodb+srv://suvedya2404:Suvedya%4024@cluster0.2iosrcb.mongodb.net/\"\n",
        "client = MongoClient(uri)\n",
        "db = client[\"test_database\"]\n",
        "collection = db[\"test_collection\"]\n",
        "\n",
        "# Ensure index on 'topic' for uniqueness\n",
        "collection.create_index(\"topic\", unique=True)\n",
        "\n",
        "# ------------------ GEMINI API ------------------ #\n",
        "\n",
        "def generate_debate_content(description, api_key):\n",
        "    print(\"\\n[🔍 Gemini API Triggered]\")\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    try:\n",
        "        response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=[description])\n",
        "        print(\"[✅ Response received]\")\n",
        "        return response.text if hasattr(response, \"text\") else str(response)\n",
        "    except Exception as e:\n",
        "        print(f\"[❌ Gemini error]: {str(e)}\")\n",
        "        return f\"Error generating content: {str(e)}\"\n",
        "\n",
        "# ------------------ HISTORY HANDLING ------------------ #\n",
        "\n",
        "def get_argument_history(topic):\n",
        "    doc = collection.find_one({\"topic\": topic})\n",
        "    if not doc:\n",
        "        return \"\"\n",
        "    turns = doc.get(\"turns\", [])\n",
        "    turns = sorted(turns, key=lambda x: x['timestamp'])\n",
        "    return \"\\n\".join([f\"{t['speaker'].capitalize()}: {t['text']}\" for t in turns])\n",
        "\n",
        "# ------------------ GRADIO INTERFACE ------------------ #\n",
        "\n",
        "# Function for Gradio interface\n",
        "def debate_system(debate_topic, user_argument):\n",
        "    now = datetime.utcnow()\n",
        "\n",
        "    # Create topic if it doesn't exist\n",
        "    if not collection.find_one({\"topic\": debate_topic}):\n",
        "        try:\n",
        "            collection.insert_one({\n",
        "                \"topic\": debate_topic,\n",
        "                \"created_at\": now,\n",
        "                \"turns\": []\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error creating topic: {e}\")\n",
        "\n",
        "    # Show past arguments (use MongoDB history function)\n",
        "    history = get_argument_history(debate_topic)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert debate assistant. Here's the debate topic: \"{debate_topic}\"\n",
        "\n",
        "    The user's latest argument: \"{user_argument}\"\n",
        "\n",
        "    Here is prior context (if any):\n",
        "    {history}\n",
        "\n",
        "    1. Analyze the stance (for/against/neutral).\n",
        "    2. Analyze the emotional tone.\n",
        "    3. Generate a strong counterargument.\n",
        "\n",
        "    Directly give the argument, no AI style, normal text please.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate AI response\n",
        "    ai_response = generate_debate_content(prompt, api_key)\n",
        "\n",
        "    turn_entries = [\n",
        "        {\n",
        "            \"speaker\": \"user\",\n",
        "            \"text\": user_argument,\n",
        "            \"timestamp\": now\n",
        "        },\n",
        "        {\n",
        "            \"speaker\": \"AI\",\n",
        "            \"text\": ai_response,\n",
        "            \"timestamp\": datetime.utcnow()\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Store debate turn in MongoDB\n",
        "    collection.update_one(\n",
        "        {\"topic\": debate_topic},\n",
        "        {\"$push\": {\"turns\": {\"$each\": turn_entries}}}\n",
        "    )\n",
        "\n",
        "    # Returning both the AI counterargument and the history\n",
        "    updated_history = get_argument_history(debate_topic)\n",
        "    return ai_response, updated_history\n",
        "\n",
        "# ------------------ NETWORK TEST ------------------ #\n",
        "\n",
        "def test_network():\n",
        "    try:\n",
        "        res = requests.get(\"https://www.google.com\")\n",
        "        return \"✅ Internet works in Gradio.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ No internet in Gradio: {e}\"\n",
        "\n",
        "# ------------------ GRADIO LAYOUT ------------------ #\n",
        "\n",
        "def create_interface():\n",
        "    # Step 1: Test network connectivity first\n",
        "    network_status = test_network()\n",
        "    print(f\"[🔌 Network Test Result]: {network_status}\")\n",
        "\n",
        "    # Step 2: Define Gradio interface\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Gemini API + Gradio Debate System\")\n",
        "        with gr.Row():\n",
        "            topic = gr.Textbox(label=\"Debate Topic\", placeholder=\"Enter debate topic here.\")\n",
        "            user_input = gr.Textbox(label=\"Your Argument\", placeholder=\"Enter your argument here.\", lines=3)\n",
        "        with gr.Row():\n",
        "            ai_output = gr.TextArea(label=\"Gemini's Counterargument\", lines=5, interactive=False)\n",
        "            history_display = gr.TextArea(label=\"Debate History\", lines=10, interactive=False)\n",
        "        submit_btn = gr.Button(\"Generate Counterargument\")\n",
        "\n",
        "        submit_btn.click(fn=debate_system,\n",
        "                         inputs=[topic, user_input],\n",
        "                         outputs=[ai_output, history_display])\n",
        "\n",
        "    # Step 3: Launch the Gradio interface\n",
        "    demo.launch()\n",
        "\n",
        "# Execute the Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    create_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "rJO4R7NLF_97",
        "outputId": "5d4a161d-224e-43b5-fad6-b590e74d879c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[🔌 Network Test Result]: ✅ Internet works in Gradio.\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://80bc2924640db07721.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://80bc2924640db07721.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install -q gradio google-generativeai pymongo gTTS SpeechRecognition requests dnspython"
      ],
      "metadata": {
        "id": "IkCI0AcKGIoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7cd34fa-f3ec-46f0-9441-72de306b7689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from google import genai\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import requests\n",
        "import tempfile\n",
        "\n",
        "# ------------------ CONFIG ------------------ #\n",
        "\n",
        "api_key = \"AIzaSyCRePOXa5qHS39yIy33Bp0dc36YehsL1pA\"  # Replace with your Gemini API key\n",
        "\n",
        "uri = \"mongodb+srv://suvedya2404:Suvedya%4024@cluster0.2iosrcb.mongodb.net/\"\n",
        "client = MongoClient(uri)\n",
        "db = client[\"test_database\"]\n",
        "collection = db[\"test_collection\"]\n",
        "collection.create_index(\"topic\", unique=True)\n",
        "\n",
        "# ------------------ GEMINI API ------------------ #\n",
        "\n",
        "def generate_debate_content(description, api_key):\n",
        "    print(\"\\n[🔍 Gemini API Triggered]\")\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    try:\n",
        "        response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=[description])\n",
        "        print(\"[✅ Response received]\")\n",
        "        return response.text if hasattr(response, \"text\") else str(response)\n",
        "    except Exception as e:\n",
        "        print(f\"[❌ Gemini error]: {str(e)}\")\n",
        "        return f\"Error generating content: {str(e)}\"\n",
        "\n",
        "# ------------------ HISTORY ------------------ #\n",
        "\n",
        "def get_argument_history(topic):\n",
        "    doc = collection.find_one({\"topic\": topic})\n",
        "    if not doc:\n",
        "        return \"\"\n",
        "    turns = sorted(doc.get(\"turns\", []), key=lambda x: x['timestamp'])\n",
        "    return \"\\n\".join([f\"{t['speaker'].capitalize()}: {t['text']}\" for t in turns])\n",
        "\n",
        "# ------------------ MAIN DEBATE FUNCTION ------------------ #\n",
        "\n",
        "def debate_system(debate_topic, user_argument):\n",
        "    now = datetime.utcnow()\n",
        "\n",
        "    if not collection.find_one({\"topic\": debate_topic}):\n",
        "        try:\n",
        "            collection.insert_one({\"topic\": debate_topic, \"created_at\": now, \"turns\": []})\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error creating topic: {e}\")\n",
        "\n",
        "    history = get_argument_history(debate_topic)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert debate assistant. Here's the debate topic: \"{debate_topic}\"\n",
        "\n",
        "    The user's latest argument: \"{user_argument}\"\n",
        "\n",
        "    Here is prior context (if any):\n",
        "    {history}\n",
        "\n",
        "    1. Analyze the stance (for/against/neutral).\n",
        "    2. Analyze the emotional tone.\n",
        "    3. Generate a strong counterargument.\n",
        "\n",
        "    Directly give the argument, no AI style, normal text please.\n",
        "    \"\"\"\n",
        "\n",
        "    ai_response = generate_debate_content(prompt, api_key)\n",
        "\n",
        "    turn_entries = [\n",
        "        {\"speaker\": \"user\", \"text\": user_argument, \"timestamp\": now},\n",
        "        {\"speaker\": \"AI\", \"text\": ai_response, \"timestamp\": datetime.utcnow()}\n",
        "    ]\n",
        "\n",
        "    collection.update_one(\n",
        "        {\"topic\": debate_topic},\n",
        "        {\"$push\": {\"turns\": {\"$each\": turn_entries}}}\n",
        "    )\n",
        "\n",
        "    updated_history = get_argument_history(debate_topic)\n",
        "    return ai_response, updated_history\n",
        "\n",
        "# ------------------ TEXT TO SPEECH ------------------ #\n",
        "\n",
        "def speak_response(text):\n",
        "    try:\n",
        "        tts = gTTS(text)\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
        "        tts.save(temp_file.name)\n",
        "        return temp_file.name\n",
        "    except Exception as e:\n",
        "        return f\"Error generating speech: {e}\"\n",
        "\n",
        "# ------------------ SPEECH TO TEXT ------------------ #\n",
        "\n",
        "def transcribe_audio(audio):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            return f\"Could not transcribe: {e}\"\n",
        "\n",
        "# ------------------ GRADIO INTERFACE ------------------ #\n",
        "\n",
        "def create_interface():\n",
        "    network_status = test_network()\n",
        "    print(f\"[🔌 Network Test Result]: {network_status}\")\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# 🎤 Debatable: Debate Transcript Analyser\")\n",
        "        gr.Markdown(\"Enter topic and argument (text or voice), get counterargument + playback\")\n",
        "\n",
        "        with gr.Row():\n",
        "            topic = gr.Textbox(label=\"Debate Topic\", placeholder=\"Enter debate topic\")\n",
        "\n",
        "        with gr.Row():\n",
        "            user_input = gr.Textbox(label=\"Your Argument\", placeholder=\"Type your argument here\", lines=3)\n",
        "            mic_input = gr.Audio(label=\"Or Speak Your Argument\", type=\"filepath\")\n",
        "\n",
        "        with gr.Row():\n",
        "            ai_output = gr.TextArea(label=\"Gemini's Counterargument\", lines=5, interactive=False)\n",
        "            history_display = gr.TextArea(label=\"Debate History\", lines=10, interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            audio_output = gr.Audio(label=\"Listen to AI\", type=\"filepath\")\n",
        "\n",
        "        def handle_submit(debate_topic, user_input, mic_path):\n",
        "            if not user_input and mic_path:\n",
        "                user_input = transcribe_audio(mic_path)\n",
        "            ai_reply, history = debate_system(debate_topic, user_input)\n",
        "            audio_reply = speak_response(ai_reply)\n",
        "            return ai_reply, history, audio_reply\n",
        "\n",
        "        submit_btn = gr.Button(\"Submit\")\n",
        "        submit_btn.click(fn=handle_submit,\n",
        "                         inputs=[topic, user_input, mic_input],\n",
        "                         outputs=[ai_output, history_display, audio_output])\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "def test_network():\n",
        "    try:\n",
        "        res = requests.get(\"https://www.google.com\")\n",
        "        return \"✅ Internet works in Gradio.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ No internet in Gradio: {e}\"\n",
        "\n",
        "# ------------------ RUN ------------------ #\n",
        "\n",
        "create_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "Y8poXIZCGS0r",
        "outputId": "8903718e-f82c-4082-f0af-7b4ea66888b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[🔌 Network Test Result]: ✅ Internet works in Gradio.\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e5ee470175209863e7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e5ee470175209863e7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ks08isNSGdXU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}